# Case-Study-2-CommonLit-Readability
This case study is on the Kaggle competition "CommonLit Readability Prize" .Rate the complexity of literary passages for grades 3-12 classroom use.
In this competition, we're predicting the reading ease of excerpts from literature. We've provided excerpts from several time periods and a wide range of reading ease scores. 
Test set includes a slightly larger proportion of modern texts (the type of texts we want to generalize to) than the training set.
This is a NLP Problem where we have to try different NLP models. Then ensemble them using various ensemble techniques.
We will be using various NLP Models like (Roberta-Base, Roberta-Large, Deberta, Electra, etc.).We also be using various fine-tuning strategies like 
Concatenate last 4 layer, Attention Head, Layer-wise Learning Rate Decay (LLRD), Frequent Evaluation.
